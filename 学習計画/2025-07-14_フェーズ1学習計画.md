# フェーズ1：基礎知識の磐石化 - 学習計画

## 概要

このドキュメントは、学習ロードマップのフェーズ1「基礎知識の磐石化」を達成するための具体的なアクションプランと、学習の記録を管理するためのものです。

**目標:** データ分析と機械学習の「お作法」を完全にマスターし、各ステップの「なぜ？」を説明できるようにする。
**期間:** 3週間

---

## 週ごとのアクションプラン

### 【1週目】 タイタニック再挑戦（EDA・前処理編）

*   **目標:** 自分の力でデータを読み込み、分析し、モデルに投入できる形に整える。
*   **アクション:**
    1.  **リポジトリのクリーンアップ:** `submission.csv`や`*_processed.csv`のような、前回の分析で生成されたファイルを一度削除し、まっさらな状態から始める。
    2.  **EDA (探索的データ分析) の実践:**
        *   `train.csv`を`pandas`で読み込む。
        *   各カラム（特徴量）のデータ型、欠損値の有無を確認する (`.info()`, `.isnull().sum()`)。
        *   `describe()`を使って数値データの基本統計量（平均、標準偏差など）を把握する。
        *   **仮説構築と検証:**
            *   `analyze_sex.py`や`analyze_pclass.py`の処理を参考に、「性別」「チケットクラス」と生存率の関係を改めて可視化し、どんな傾向があるか自分の言葉で説明してみる。
            *   上記以外に、生存率に関係しそうな特徴量はどれか、新たに見つけて可視化してみる。（例：「年齢と生存率」「乗船港と生存率」など）
    3.  **特徴量エンジニアリング:**
        *   欠損値をどう補うか、なぜその方法を選ぶのかを考える（例: 年齢の欠損値を中央値で埋めるのはなぜか？）。
        *   カテゴリ変数（性別、乗船港など）を、モデルが学習できる数値に変換する。
        *   新しい特徴量を作成してみる（例: `SibSp`と`Parch`を合わせて「家族サイズ」という特徴量を作る）。
*   **学習メモ:**
    *   (ここに、1週目で学んだこと、気づいたこと、疑問点などを自由に記述してください)

---

### 【2週目】 タイタニック再挑戦（モデル構築・評価・提出編）

*   **目標:** モデルを学習させ、評価し、Kaggleに提出できるファイルを作成する。
*   **アクション:**
    1.  **モデルの学習:**
        *   1週目で作成した前処理済みのデータを、訓練用と検証用に分割する (`train_test_split`)。
        *   ロジスティック回帰モデル (`LogisticRegression`) をインスタンス化し、訓練用データで学習させる (`.fit()`)。
    2.  **モデルの評価:**
        *   検証用データを使って、モデルの精度を評価する (`.predict()`, `accuracy_score`)。
        *   **なぜAccuracyなのか？** 今回のタスクでAccuracyが適切な評価指標である理由を考える。また、不均衡なデータ（例: 癌の陽性/陰性予測）ではAccuracyが不適切になるケースを調べる。
        *   **混同行列 (Confusion Matrix)** とは何かを調べ、今回のモデルの混同行列を作成し、Precision, Recall, F1-scoreも計算してみる。
    3.  **予測と提出:**
        *   `test.csv`に対しても、`train.csv`と**全く同じ前処理**を施す。
        *   学習済みモデルを使って、乗客の生存を予測する。
        *   Kaggleの提出フォーマット (`gender_submission.csv`) に合わせて、`submission.csv`を作成する。
*   **学習メモ:**
    *   (ここに、2週目で学んだこと、気づいたこと、疑問点などを自由に記述してください)

---

### 【3週目】 知識の整理とライブラリ探訪

*   **目標:** 今回の分析で使った技術の「なぜ」を深掘りし、関連知識を広げる。
*   **アクション:**
    1.  **公式ドキュメントに触れる:**
        *   **pandas:** `groupby`, `merge`, `pivot_table`など、データを集計・結合するための強力な関数について、チートシートやドキュメントで使い方を確認する。
        *   **scikit-learn:** 今回使った`LogisticRegression`以外にどんな分類モデルがあるか、公式の[アルゴリズムチートシート](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)を眺めてみる。
    2.  **知識の言語化:**
        *   このファイルに、以下の問いに対する自分なりの答えを書き出してみる。
            *   EDAの目的は何か？
            *   特徴量エンジニアリングは、なぜモデルの精度に重要なのか？
            *   モデルの評価指標を、なぜ複数知っておく必要があるのか？
*   **学習メモ:**
    *   (ここに、3週目で学んだこと、気づいたこと、疑問点などを自由に記述してください)
